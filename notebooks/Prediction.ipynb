{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by predicting using the maskrcnn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "path = 'x/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'x/'\n",
    "outputPath = 'outputVal/maskrcnn/'\n",
    "os.makedirs(outputPath,exist_ok=True)\n",
    "transforms = get_transform(train=False)\n",
    "for imName in list(sorted(os.listdir(path))):\n",
    "    \n",
    "    model = torch.jit.load(\"instanceSegmentation.pth\")\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    #img, _ = dataset_test[i]\n",
    "    img = Image.open(path+imName).convert(\"RGB\")\n",
    "    # Aqui hay que transformar la imagen con los transforms. \n",
    "    img,_ = transforms(img,img)\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img.to(device)])\n",
    "        \n",
    "    im = prediction[1][0]['masks'][0, 0].mul(255).byte().cpu().numpy()\n",
    "    for j in range(1,len(prediction[1][0]['masks'])): \n",
    "        im = np.maximum(im,prediction[1][0]['masks'][j, 0].mul(255).byte().cpu().numpy())\n",
    "    \n",
    "    ima = Image.fromarray(im)\n",
    "    # Guardar con el nombre adecuado. \n",
    "    ima.save(outputPath+imName)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make the predictions using the HRNet model that obtains both the cytoplasm and the nucleus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# HRNet\n",
    "\n",
    "model = torch.jit.load(\"hrnet.pth\")\n",
    "model = model.cpu()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "def transform_image(image):\n",
    "    my_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(\n",
    "                                            [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])])\n",
    "    image_aux = image\n",
    "    return my_transforms(image_aux).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision import models\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "inputpath = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = 'outputVal/hrnet/'\n",
    "os.makedirs(outputPath,exist_ok=True)\n",
    "for file in inputpath.ls():\n",
    "    image = Image.open(file)\n",
    "    h,w=image.shape\n",
    "    image = transforms.Resize((1000,1333))(image)\n",
    "    tensor = transform_image(image=image)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tensor)\n",
    "    outputs = torch.argmax(outputs,1)\n",
    "    mask = np.array(outputs.cpu())\n",
    "    mask[mask==1]=20\n",
    "    mask[mask==2]=40\n",
    "    mask=np.reshape(mask,(1000*1333))\n",
    "    new  = np.zeros((1000*1333,3),dtype='uint8')\n",
    "\n",
    "    for i,v in enumerate(mask):\n",
    "        new[i]=[v,v,v]\n",
    "\n",
    "\n",
    "    maskRGBShow = Image.fromarray(np.reshape(new,(1000,1333,3)))\n",
    "    maskRGBShow.save(outputPath+file.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make the predictions using the Deeplab model that obtains both the cytoplasm and the nucleus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# HRNet\n",
    "\n",
    "model = torch.jit.load(\"deeplab.pth\")\n",
    "model = model.cpu()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = 'outputVal/deeplab/'\n",
    "os.makedirs(outputPath,exist_ok=True)\n",
    "for file in inputpath.ls():\n",
    "    image = Image.open(file)\n",
    "    h,w=image.shape\n",
    "    image = transforms.Resize((1000,1333))(image)\n",
    "    tensor = transform_image(image=image)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tensor)\n",
    "    outputs = torch.argmax(outputs,1)\n",
    "    mask = np.array(outputs.cpu())\n",
    "    mask[mask==1]=20\n",
    "    mask[mask==2]=40\n",
    "    mask=np.reshape(mask,(1000*1333))\n",
    "    new  = np.zeros((1000*1333,3),dtype='uint8')\n",
    "\n",
    "    for i,v in enumerate(mask):\n",
    "        new[i]=[v,v,v]\n",
    "\n",
    "\n",
    "    maskRGBShow = Image.fromarray(np.reshape(new,(1000,1333,3)))\n",
    "    maskRGBShow.save(outputPath+file.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combine the predictions of the hrnet and deeplab models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnnPath = 'outputVal/maskrcnn/'\n",
    "hrnetPath = 'outputVal/hrnet/'\n",
    "deeplabPath = 'outputVal/deeplab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputModelsPath = 'outputVal/combination/'\n",
    "os.makedirs(outputModelsPath,exist_ok=True)\n",
    "\n",
    "for imName in list(sorted(os.listdir(path))):\n",
    "    im1 = cv2.imread(maskrcnnPath+imName)\n",
    "    (h,w,d) = im1.shape\n",
    "    im2 = cv2.imread(hrnetPath+imName)\n",
    "    im2 = cv2.resize(im2,(w,h))\n",
    "    \n",
    "    im3 = cv2.imread(deeplabPath+imName)\n",
    "    im3 = cv2.resize(im3,(w,h))\n",
    "    \n",
    "    im2 = np.maximum(im2,im3)\n",
    "    \n",
    "    cv2.imwrite(outputModelsPath+imName,im2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
